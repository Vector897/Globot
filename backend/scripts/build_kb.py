"""
çŸ¥è¯†åº“æ„å»ºè„šæœ¬
å¤„ç†å¤§ç–†äº§å“æ‰‹å†ŒPDFå¹¶å‘é‡åŒ–åˆ°Chroma
"""
import os
import sys
from pathlib import Path
import logging

# æ·»åŠ backendåˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Try importing KnowledgeBase Service (Should work now as it handles missing deps)
try:
    from services.knowledge_base import get_knowledge_base
except ImportError:
    logger.warning("Could not import get_knowledge_base. Using dummy.")
    def get_knowledge_base():
        class DummyKB:
            def search(self, *args, **kwargs): return []
            def add_documents(self, *args, **kwargs): pass
        return DummyKB()

# Optional LangChain Imports
try:
    from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    HAS_LIBS = True
except ImportError:
    HAS_LIBS = False
    logger.warning("LangChain libraries not found. Build will skip ingestion.")

# äº§å“æ–‡æ¡£è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
DOCS_PATH = "../../Project_Info"

# äº§å“æ˜ å°„
PRODUCT_MAPPING = {
    "Matrice_400": "M400",
    "Matrice30": "M30", 
    "Matrice_4D": "Dock3",
    "Dock_3": "Dock3",
    "D-RTK": "RTK",
    "DJI_Cellular": "Accessories",
    "DJI_AS1": "Accessories"
}

def detect_product_tag(filename: str) -> str:
    """ä»æ–‡ä»¶åæ£€æµ‹äº§å“æ ‡ç­¾"""
    for key, tag in PRODUCT_MAPPING.items():
        if key in filename:
            return tag
    return "General"

def detect_doc_type(filename: str) -> str:
    """ä»æ–‡ä»¶åæ£€æµ‹æ–‡æ¡£ç±»å‹"""
    filename_lower = filename.lower()
    if 'faq' in filename_lower:
        return 'faq'
    elif 'user_manual' in 'user manual' in filename_lower:
        return 'manual'
    elif 'maintenance' in filename_lower:
        return 'maintenance'
    elif 'installation' in filename_lower or 'setup' in filename_lower:
        return 'installation'
    elif 'safety' in filename_lower:
        return 'safety'
    else:
        return 'manual'

def build_knowledge_base():
    """æ„å»ºçŸ¥è¯†åº“"""
    logger.info("ğŸš€ å¼€å§‹æ„å»ºçŸ¥è¯†åº“...")
    
    if not HAS_LIBS:
        logger.info("âš ï¸ ç¼ºå°‘ä¾èµ– (LangChain ç­‰)ï¼Œè·³è¿‡å®é™…æ„å»ºã€‚ç”±äºå¤„äº Mock å¼€å‘æ¨¡å¼ï¼Œè¿™æ˜¯å…è®¸çš„ã€‚")
        return

    # 1. è·å–æ–‡æ¡£è·¯å¾„
    docs_dir = Path(__file__).parent.parent / DOCS_PATH
    if not docs_dir.exists():
        logger.error(f"æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {docs_dir}")
        return
    
    # 2. åˆå§‹åŒ–å‘é‡åº“
    kb = get_knowledge_base()
    
    # 3. æ–‡æœ¬åˆ†å‰²å™¨
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", "ã€‚", "ï¼Œ", " ", ""]
    )
    
    # 4. å¤„ç†æ‰€æœ‰æ–‡æ¡£
    all_documents = []
    file_count = 0
    
    for file_path in docs_dir.glob("**/*"):
        if not file_path.is_file():
            continue
        
        # ä»…å¤„ç†PDFã€DOCXå’ŒTXT
        if file_path.suffix.lower() not in ['.pdf', '.docx', '.txt']:
            continue
        
        logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path.name}")
        
        try:
            # åŠ è½½æ–‡æ¡£
            if file_path.suffix.lower() == '.pdf':
                loader = PyPDFLoader(str(file_path))
            elif file_path.suffix.lower() == '.txt':
                # TXTæ–‡ä»¶ç›´æ¥è¯»å–
                from langchain_core.documents import Document
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                raw_docs = [Document(page_content=text, metadata={"source": str(file_path)})]
            else:
                loader = Docx2txtLoader(str(file_path))
            
            if file_path.suffix.lower() != '.txt':
                raw_docs = loader.load()
            
            # æ£€æµ‹äº§å“å’Œç±»å‹
            product_tag = detect_product_tag(file_path.name)
            doc_type = detect_doc_type(file_path.name)
            
            # åˆ†å—
            chunks = text_splitter.split_documents(raw_docs)
            
            # æ·»åŠ å…ƒæ•°æ®
            for chunk in chunks:
                chunk.metadata.update({
                    'source_file': file_path.name,
                    'product_tag': product_tag,
                    'doc_type': doc_type
                })
            
            all_documents.extend(chunks)
            file_count += 1
            logger.info(f"  âœ… æˆåŠŸ: {len(chunks)} ä¸ªæ–‡æœ¬å—, äº§å“:{product_tag}, ç±»å‹:{doc_type}")
            
        except Exception as e:
            logger.error(f"  âŒ å¤±è´¥: {e}")
            continue
    
    # 5. æ‰¹é‡æ·»åŠ åˆ°å‘é‡åº“
    if all_documents:
        logger.info(f"\nğŸ“Š å…±å¤„ç† {file_count} ä¸ªæ–‡ä»¶, {len(all_documents)} ä¸ªæ–‡æœ¬å—")
        logger.info("ğŸ”„ æ­£åœ¨å‘é‡åŒ–å¹¶å­˜å‚¨åˆ°Chroma...")
        
        kb.add_documents(all_documents)
        
        logger.info("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
    else:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£")

def test_knowledge_base():
    """æµ‹è¯•çŸ¥è¯†åº“æ£€ç´¢"""
    logger.info("\nğŸ§ª æµ‹è¯•çŸ¥è¯†åº“æ£€ç´¢...")
    
    kb = get_knowledge_base()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        ("Matrice 30çš„ç»­èˆªæ—¶é—´æ˜¯å¤šå°‘ï¼Ÿ", "M30"),
        ("Dock 3å¦‚ä½•å®‰è£…ï¼Ÿ", "Dock3"),
        ("M400çš„ä¿å…»å‘¨æœŸ", "M400"),
        ("RTKå®šä½ç²¾åº¦", "RTK")
    ]
    
    for query, product in test_queries:
        logger.info(f"\næŸ¥è¯¢: {query} (äº§å“: {product})")
        results = kb.search(query, product_filter=product, top_k=2)
        
        if results:
            for i, doc in enumerate(results, 1):
                logger.info(f"  ç»“æœ{i}: [{doc.metadata.get('product_tag')}] {doc.page_content[:100]}...")
        else:
            logger.warning("  æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ„å»ºå¤§ç–†äº§å“çŸ¥è¯†åº“")
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•çŸ¥è¯†åº“æ£€ç´¢')
    args = parser.parse_args()
    
    if args.test:
        test_knowledge_base()
    else:
        build_knowledge_base()
        logger.info("\nğŸ’¡ è¿è¡Œ 'python build_kb.py --test' æµ‹è¯•æ£€ç´¢")
